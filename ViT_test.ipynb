{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((2,3,224,224))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "224,224,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([2, 3, 224, 224])\n",
      "shape torch.Size([2, 768, 14, 14])\n",
      "flatten shape: torch.Size([2, 768, 196])\n",
      "transpose shape: torch.Size([2, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2,3,224,224))\n",
    "print('x shape:',x.shape)\n",
    "img_size = 224\n",
    "patch_size = 16\n",
    "in_c = 3\n",
    "grid_size = img_size // patch_size  # 14\n",
    "num_patches = grid_size * grid_size # 196\n",
    "embed_dim = 768\n",
    "\n",
    "proj = nn.Conv2d(in_c,embed_dim,kernel_size=patch_size,stride=patch_size)\n",
    "x = proj(x)\n",
    "print('shape',x.shape)\n",
    "x_flatten = x.flatten(start_dim=2)\n",
    "print('flatten shape:',x_flatten.shape)\n",
    "x_transpose = x_flatten.transpose(1,2)\n",
    "print('transpose shape:',x_transpose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class token shape: torch.Size([1, 1, 768])\n",
      "class token shape: torch.Size([2, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "cls_token = nn.Parameter(torch.zeros(1,1,embed_dim))\n",
    "print('class token shape:',cls_token.shape)\n",
    "cls_token = cls_token.expand(x.shape[0],-1,-1)\n",
    "print('class token shape:',cls_token.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat class token shape: torch.Size([2, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cat((cls_token, x_transpose), dim=1)\n",
    "print('cat class token shape:',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos embedding shape torch.Size([2, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "pos_drop = nn.Dropout(p=0.1)\n",
    "pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "x = pos_drop(x+pos_embed)\n",
    "print('pos embedding shape',x.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = embed_dim  # 768\n",
    "num_heads = 8\n",
    "head_dim = dim // num_heads  # 96\n",
    "scale = head_dim ** -.5\n",
    "qkv = nn.Linear(dim,dim*3,bias=False)\n",
    "proj = nn.Linear(dim, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qkv: torch.Size([2, 197, 2304])\n",
      "qkv reshape shape: torch.Size([2, 197, 3, 8, 96])\n",
      "torch.Size([3, 2, 8, 197, 96])\n"
     ]
    }
   ],
   "source": [
    "B,N,C = x.shape\n",
    "x_qkv = qkv(x)\n",
    "print('qkv:',x_qkv.shape)\n",
    "x_qkv = x_qkv.reshape(B,N,3,num_heads,C//num_heads)\n",
    "print('qkv reshape shape:',x_qkv.shape)\n",
    "x_qkv = x_qkv.permute(2,0,3,1,4) # qkv, batch, head, token, embed\n",
    "print(x_qkv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qkv shape: torch.Size([2, 8, 197, 96]) torch.Size([2, 8, 197, 96]) torch.Size([2, 8, 197, 96])\n"
     ]
    }
   ],
   "source": [
    "x_qkv = qkv(x).reshape(B,N,3,num_heads,C//num_heads).permute(2,0,3,1,4)\n",
    "q,k,v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "print('qkv shape:',q.shape,k.shape,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn shape: torch.Size([2, 8, 197, 197])\n",
      "attn shape: torch.Size([2, 8, 197, 197])\n"
     ]
    }
   ],
   "source": [
    "attn = q @ k.transpose(-2,-1) * scale\n",
    "print('attn shape:',attn.shape)\n",
    "attn = attn.softmax(dim=-1)\n",
    "print('attn shape:',attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 197, 96])\n",
      "torch.Size([2, 197, 8, 96])\n",
      "torch.Size([2, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "x = (attn @ v)\n",
    "print(x.shape)\n",
    "x = x.transpose(2,1)\n",
    "print(x.shape)\n",
    "x = x.reshape(B,N,C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "x = proj(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 197, 2304])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((2,197,768))\n",
    "B,N,C = x.shape\n",
    "dim = C\n",
    "qkv = nn.Linear(dim,dim*3,bias=False)\n",
    "x_qkv = qkv(x)\n",
    "x_qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6650, 0.1043, 0.4476, 0.2958],\n",
       "          [0.6112, 0.5947, 0.1497, 0.4887],\n",
       "          [0.5964, 0.5270, 0.5247, 0.1507]],\n",
       " \n",
       "         [[0.3382, 0.4961, 0.9240, 0.1225],\n",
       "          [0.8432, 0.3558, 0.6870, 0.9859],\n",
       "          [0.1601, 0.4467, 0.8009, 0.7571]]]),\n",
       " tensor([[[0.8312, 0.1304, 0.5595, 0.3698],\n",
       "          [0.7640, 0.7434, 0.1871, 0.6108],\n",
       "          [0.7454, 0.6588, 0.6559, 0.1884]],\n",
       " \n",
       "         [[0.4228, 0.6201, 1.1550, 0.1531],\n",
       "          [1.0540, 0.4448, 0.8588, 1.2323],\n",
       "          [0.2001, 0.5583, 1.0011, 0.9463]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### droppath\n",
    "\n",
    "x = torch.rand((2,3,4))\n",
    "drop_prob = 0.2\n",
    "keep_porb = 1 - drop_prob  # 0.8\n",
    "shape = (x.shape[0],) + (1,) * (x.ndim - 1) # (2,1,1)\n",
    "random_tensor = keep_porb + torch.rand(shape)\n",
    "random_tensor.floor_()\n",
    "output = x.div(keep_porb) * random_tensor\n",
    "x,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d0b924d46175125b2288e35b7e96bc220e2e674c3c0a3172562eac2975018cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
